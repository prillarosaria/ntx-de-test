{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup  # library utama untuk melakukan scrapping\n",
    "import requests                # library untuk mendapatkan HTTP request\n",
    "import unicodedata             # library untuk membersihkan unicode yang terbawa\n",
    "import pandas as pd            # library untuk membuat data frame\n",
    "import asyncio\n",
    "import polars as pl\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi untuk mengambil data title dan link pada website dengan memasukkan baris data yang telah discraping dan barchart untuk loading\n",
    "#saat get data\n",
    "def get(row, bar, page, level):\n",
    "    #mencari tag HTML 'b' yang merupakan tag dari title\n",
    "    error = []\n",
    "    title_tag = row.find('b')\n",
    "    try:\n",
    "        #jika title ada, maka\n",
    "        if title_tag:\n",
    "            #ambil data title\n",
    "            title = title_tag.get_text()\n",
    "            #ambil data link\n",
    "            link = row['onclick'].split('=')[1].strip()\n",
    "            #mengupdate bar agar bertambah\n",
    "            bar.update(1)\n",
    "    except:\n",
    "        error.append(page)\n",
    "\n",
    "    return {'title' : title, 'link' : \"https://www.fortiguard.com\" + link[1:-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi untuk membuat file dataset csv berdasarkan level\n",
    "def into_csv(values, level):\n",
    "    name = f\"forti_lists_{level}.csv\"\n",
    "    error_csv = []\n",
    "\n",
    "    try:\n",
    "        #jika file csv telah terdapat pada folder, maka file tersebut yang akan digunakan\n",
    "        df = pl.read_csv(name)\n",
    "    except:\n",
    "        data = {\n",
    "            'title': [],\n",
    "            'link': []\n",
    "        }\n",
    "        #jika file csv pada level tersebut belum ada, maka akan menggunakan file baru\n",
    "        df = pl.DataFrame(data)\n",
    "\n",
    "    #Menambahkan data title dan link pada dataframe untuk dimasukkan dalam file csv\n",
    "    add_df = pl.DataFrame(values)\n",
    "\n",
    "    #Memasukkan menambah data title dan link yang baru ke csv\n",
    "    df.extend(add_df)\n",
    "    df.write_csv(name)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fungsi untuk melakukan scraping data menggunakan library BeautifulSoup\n",
    "def get_data(level, page, bar):\n",
    "    url = f\"https://www.fortiguard.com/encyclopedia?type=ips&risk={level}&page={page}\"\n",
    "    \n",
    "    #Melakukan request untuk url website\n",
    "    page = requests.get(url)\n",
    "\n",
    "    #Melakukan parsing code HTML menjadi bentuk teks\n",
    "    soup = BeautifulSoup(page.text, \"html.parser\")\n",
    "\n",
    "    #Memilih tag HTML yang mengandung data penting yang dibutuhkan\n",
    "    body = soup.select(\"section.table-body > div.container > div.row\")\n",
    "\n",
    "    #Mengambil data title dan link\n",
    "    values = [get(row, bar, page, level) for row in body]\n",
    "\n",
    "    #Memasukkan data pada file csv\n",
    "    into_csv(values, level)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "20it [05:13, 15.68s/it]\n",
      "20it [06:51, 20.56s/it]\n",
      "20it [04:38, 13.92s/it]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A"
     ]
    }
   ],
   "source": [
    "#Max pages sudah ditentukan berdasarkan jumlah page maksimal pada website\n",
    "max_pages = [7, 34, 170, 386, 248]\n",
    "#Total data tiap level sudah ditentukan dengan melihat data pada website\n",
    "total_data = [127, 662, 3397, 7704, 4958]\n",
    "\n",
    "data = []\n",
    "#Perulangan untuk melakukan scraping data setiap level\n",
    "for level in range(1, 6):\n",
    "    #Barchart\n",
    "    bar = tqdm(total_data[level-1])\n",
    "\n",
    "    #Mengambil data title dan link tiap level sebanyak jumlah maksimal halamannya\n",
    "    for page in range(1, max_pages[level-1]):\n",
    "        get_data(level, page, bar)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
